{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+qpCFhtMIV3UMT+fWC35Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoalfonso/M11-and-M49/blob/main/Extra_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<table style=\"width: 100%\">\n",
        "\t<tr>\n",
        "\t\t<td>\n",
        "\t\t<table style=\"width: 100%\">\n",
        "\t\t\t<tr>\n",
        "                <td ><center><font size=\"5\"><b>Modules 11 and 49</b></font><center></td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "                <td><center><font size=\"6\"><b>Extra challenges - Notebook 05</b></font><center></td>\n",
        "\t\t\t</tr>\n",
        "\t\t</table>\n",
        "\t\t</td>\n",
        "\t\t<td><center><img src='https://ihe-delft-ihe-website-production.s3.eu-central-1.amazonaws.com/s3fs-public/styles/792w/public/2022-11/IHE-DELFT-INSTITUTE_UNESCO_RGB.png?itok=-GnfBc2x'></img></td>\n",
        "\t</tr>\n",
        "</table>\n",
        "</div>"
      ],
      "metadata": {
        "id": "1kW9wkgbqckK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b94799ca"
      },
      "source": [
        "## ðŸ““ Extra challenges period 5 - Pandas\n",
        "\n",
        "### **1. Challenge: Handling Messy Data**\n",
        "\n",
        "Your `precipitation_data.csv` file was corrupted. A new file, `precipitation_messy.csv`, is provided. It has two problems:\n",
        "1.  The date format is non-standard (e.g., `01-Jan-2023`).\n",
        "2.  There are missing values, represented by the string `\"MISSING\"`.\n",
        "\n",
        "**File Content for `precipitation_messy.csv`:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date,Precipitation_mm,Station_ID\n",
        "01-Jan-2023,0.0,S1\n",
        "02-Jan-2023,5.2,S1\n",
        "03-Jan-2023,12.1,S1\n",
        "04-Jan-2023,MISSING,S1\n",
        "05-Jan-2023,0.0,S1\n",
        "06-Jan-2023,0.0,S1\n",
        "07-Jan-2023,8.4,S1\n",
        "08-Jan-2023,1.2,S1\n",
        "\n"
      ],
      "metadata": {
        "id": "nrAU_BrN2U4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:**\n",
        "1.  Create and upload this new file.\n",
        "2.  When loading with `pd.read_csv()`, use the `na_values=\"MISSING\"` argument to correctly identify missing data.\n",
        "3.  When using `pd.to_datetime()`, use the `format=\"%d-%b-%Y\"` argument to parse the specific date format.\n",
        "4.  Set the `Date` as the index.\n",
        "5.  Run `df.info()` to prove that `Precipitation_mm` is now a `float` (not `object`) and that there is one \"non-null\" value missing.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-C_JuZFz25mi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EuMNkZ7V0FFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Time-Lagged Correlation (Unit Hydrograph)**\n",
        "\n",
        "**Hydrological Context:**\n",
        "In hydrology, we often need to know the \"lag time\" or \"time of concentration\" of a catchment. This is the time it takes for rainfall (Effective Rainfall, `RE`) at the furthest point of the catchment to cause discharge (`Q`) at the outlet.\n",
        "\n",
        "We can estimate this by finding the time lag ($i$) where the correlation between $RE(t-i)$ and $Q(t+1)$ is at its maximum. This exercise will guide you through this \"systems analysis\" approach.\n",
        "\n",
        "**Data File:** `Sieve-orig.csv` (This file contains hourly data for `REt` and `Qt`).\n",
        "\n",
        "---\n",
        "\n",
        "### Task 1: Load and Prepare Data\n",
        "\n",
        "1.  Upload the `Sieve-orig.csv` file.\n",
        "2.  Load it into a Pandas DataFrame.\n",
        "3.  The time column `t` is in a non-standard format. Convert it to datetime objects using `pd.to_datetime()`. You will need to specify the format: `format='%d/%m/%Y %H:%M'`.\n",
        "4.  Set the new datetime column `t` as the index of the DataFrame.\n",
        "5.  Inspect the data with `.info()` and `.head()`.\n",
        "\n",
        "---\n",
        "\n",
        "### Task 2: Create the Time-Lagged Matrix\n",
        "\n",
        "1.  Create a new, empty DataFrame called `df_lagged`.\n",
        "2.  Create a column for `Q(t)` by copying the `'Qt'` column from your original DataFrame.\n",
        "3.  Create a column for `Q(t+1)` by **shifting** the `'Qt'` column by **-1**.\n",
        "4.  Write a `for` loop that iterates from `i = 0` to `9` (10 steps total).\n",
        "5.  Inside the loop, create a new column for each `RE` lag (e.g., `'RE_t_minus_0'`, `'RE_t_minus_1'`, ... `'RE_t_minus_9'`). This is done by **shifting** the `'REt'` column by `i`.\n",
        "6.  After creating the lagged DataFrame, use the `.dropna()` method to remove all rows that contain `NaN` values (which are artifacts of the shifting process).\n",
        "7.  Display the `.head()` of `df_lagged`.\n",
        "\n",
        "---\n",
        "\n",
        "### Task 3: Calculate Correlation\n",
        "\n",
        "1.  Calculate the full correlation matrix for `df_lagged` using the `.corr()` method.\n",
        "2.  From this matrix, select the column corresponding to `Q(t+1)`. This Series now shows how every other variable correlates with the future discharge.\n",
        "\n",
        "---\n",
        "\n",
        "### Task 4: Graph Correlation vs. Time Lag\n",
        "\n",
        "1.  From the correlation Series (from Task 3), filter for just the indices that contain `\"RE_\"`.\n",
        "2.  This new Series is difficult to plot because its index is made of strings. To fix this:\n",
        "    * Convert the Series to a DataFrame, e.g., `plot_data = pd.DataFrame({'Correlation': your_re_correlations})`.\n",
        "    * Create a new column `Lag_Hours` by extracting the number from the index strings (Hint: use `.index.str.replace('RE_t_minus_', '').astype(int)`).\n",
        "    * Sort the `plot_data` DataFrame by `Lag_Hours`.\n",
        "3.  Create a line plot of `Correlation` (y-axis) vs. `Lag_Hours` (x-axis).\n",
        "4.  Add a title and appropriate axis labels.\n",
        "\n",
        "---\n",
        "\n",
        "### Analysis (in a markdown cell):\n",
        "\n",
        "* Look at your plot. At which time lag (in hours) does the peak correlation occur?\n",
        "* What does this value represent in a hydrological context?"
      ],
      "metadata": {
        "id": "jQ9S9EhgMl6g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBp2up4kNeJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}